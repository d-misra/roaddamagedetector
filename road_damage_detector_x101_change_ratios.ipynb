{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy train/tests folders\n",
    "To avoid uploading large file size, the train, test1, and test2 folders are removed from our submissions.\n",
    "Please kindly help to copy the folder train, test1, and test1 to this project folder (same location as this file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Installations\n",
    "Please refer to the file `requirements.txt` for the list of packages used in this program. Some of the specific machine learning libraries, there will be codes regarding installations. However, for those common libraries (such as numpy, matplotlib, etc), we assumed that already available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "Please run the following sections starting from Splitting data until before the Training.\n",
    "If you would like to continue the training process please consider increase the `max_iter` key in the configuration variable. If you do not want to run the training, it just run through the train section, it will skip the training since we've done the training.\n",
    "\n",
    "Most of the data was pre-processed so will execute quickly. Those take longer time there was the time recorded using %timeit to let the users know how long it may take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2 installations\n",
    "Make sure to install detectron2 and its dependencies by enabling the following lines if you haven't done so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # install dependencies:\n",
    "# !pip install pycocotools>=2.0.1\n",
    "# import torch\n",
    "# print(torch.__version__, torch.cuda.is_available())\n",
    "# !gcc --version\n",
    "# # Make sure also to install opencv (assumed to be pre-installed)\n",
    "# # install detectron2: (Colab has CUDA 10.1 + torch 1.6)\n",
    "# # See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "# assert torch.__version__.startswith(\"1.6\")\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stratify is by country and then by the damage type with lowest number of occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 986 ms\n"
     ]
    }
   ],
   "source": [
    "from data_processing import split_train_data, process_tests, load_train_eval_splits, load_tests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records for train split exists\n",
      "Records for evaluation split exists\n",
      "time: 394 µs\n"
     ]
    }
   ],
   "source": [
    "# Process train/evaluation splits\n",
    "split_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 exists\n",
      "test2 exists\n",
      "time: 3.27 ms\n"
     ]
    }
   ],
   "source": [
    "# Process tests\n",
    "process_tests([\"test1\", \"test2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "train_dicts, eval_dicts = load_train_eval_splits()\n",
    "test1_dicts, test2_dicts = load_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10974 1221 2631 2664\n",
      "time: 922 µs\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dicts), len(eval_dicts), len(test1_dicts), len(test2_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "See split balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 199 ms\n"
     ]
    }
   ],
   "source": [
    "from vis_utils import plot_damage_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 5923\n",
      "1 : 3992\n",
      "2 : 7513\n",
      "3 : 5044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5923, 3992, 7513, 5044]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "plot_damage_distributions(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 669\n",
      "1 : 454\n",
      "2 : 868\n",
      "3 : 583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[669, 454, 868, 583]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 97.9 ms\n"
     ]
    }
   ],
   "source": [
    "plot_damage_distributions(eval_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.94 ms\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from cv2 import imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./x101_change_ratios_output'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.17 ms\n"
     ]
    }
   ],
   "source": [
    "model_type='x101_change_ratios'\n",
    "OUTPUT_DIR = f'./{model_type}_output'\n",
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[10/20 14:58:22 d2.data.datasets.coco]: \u001B[0mConverting annotations of dataset 'road_damage_train' to COCO format ...)\n",
      "\u001B[32m[10/20 14:58:22 d2.data.datasets.coco]: \u001B[0mConverting dataset dicts into COCO format\n",
      "\u001B[32m[10/20 14:58:24 d2.data.datasets.coco]: \u001B[0mConversion finished, #images: 10974, #annotations: 22472\n",
      "\u001B[32m[10/20 14:58:24 d2.data.datasets.coco]: \u001B[0mCaching COCO format annotations at './x101_change_ratios_output/road_damage_train_coco_format.json' ...\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConverting annotations of dataset 'road_damage_eval' to COCO format ...)\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConverting dataset dicts into COCO format\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConversion finished, #images: 1221, #annotations: 2574\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mCaching COCO format annotations at './x101_change_ratios_output/road_damage_eval_coco_format.json' ...\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConverting annotations of dataset 'road_damage_test1' to COCO format ...)\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConverting dataset dicts into COCO format\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConversion finished, #images: 2631, #annotations: 0\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mCaching COCO format annotations at './x101_change_ratios_output/road_damage_test1_coco_format.json' ...\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConverting annotations of dataset 'road_damage_test2' to COCO format ...)\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConverting dataset dicts into COCO format\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mConversion finished, #images: 2664, #annotations: 0\n",
      "\u001B[32m[10/20 14:58:25 d2.data.datasets.coco]: \u001B[0mCaching COCO format annotations at './x101_change_ratios_output/road_damage_test2_coco_format.json' ...\n",
      "Converted and registered: road_damage_train,  road_damage_eval, road_damage_test1, road_damage_test2\n",
      "time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "from data_processing import prepare_data\n",
    "road_damage_metadata = prepare_data(OUTPUT_DIR, train_dicts, eval_dicts, test1_dicts, test2_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OUTPUT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-b66615449dfb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtrain_helper\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconfigure_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m train_config = {\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0;34m'OUTPUT_DIR'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOUTPUT_DIR\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;34m'base_config_file'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m#'COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml', # X101 is more accurate but slow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;34m'base_weight_file'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m#'detectron2://ImageNetPretrained/MSRA/R-101.pkl', # X101 is more accurate but slow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'OUTPUT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "from train_helper import configure_model\n",
    "train_config = {\n",
    "    'OUTPUT_DIR': OUTPUT_DIR,\n",
    "    'base_config_file': \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\", #'COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml', # X101 is more accurate but slow\n",
    "    'base_weight_file': \"detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\", #'detectron2://ImageNetPretrained/MSRA/R-101.pkl', # X101 is more accurate but slow\n",
    "    'max_iter': 50000,\n",
    "    'num_gpus': 2,\n",
    "    'ims_per_batch': 16,\n",
    "    'learning_rate': 0.00025,\n",
    "    'sizes':[32, 64, 128, 256], \n",
    "    'aspect_ratios':[0.1, 0.5, 1.0, 1.5]\n",
    "}\n",
    "cfg = configure_model(**train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "If you would like to continue the training process please increase the `max_iter` field in the previous cell, otherwise you can continue to run or safely skip the training cell. If you continue to run without changing `max_iter`, since we resume from previous epochs, so it will stop (it is not an error, just continue to evaluation part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-2dab6d67d353>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmy_detectron2_trainer\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMyTrainer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcfg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOUTPUT_DIR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexist_ok\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mtrainer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMyTrainer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcfg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresume_or_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresume\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from my_detectron2_trainer import MyTrainer\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = MyTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./x101_change_ratios_output'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.17 ms\n"
     ]
    }
   ],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View training history via TensorBoard\n",
    "Please comment the cell belows if you don't have tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-98002f5eca844c04\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-98002f5eca844c04\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir x101_change_ratios_output --host localhost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations\n",
    "This section we will evaluate checkpoints at different iterations (specified in `the_max_iters` variable) and select the best model and the best object classification threshold. Tentatively 30 minutes, depending to the hardware's configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.09 ms\n"
     ]
    }
   ],
   "source": [
    "import detectron2\n",
    "import evaluator\n",
    "from evaluator import predict, evaluate_model, predict_with_tta, evaluate_models, get_evaluation_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model model_0049999\n",
      "Done inferences in 2.007821524143219 minutes at 2020-10-20 15:01:03.242726\n",
      "model_0049999 max f1 0.5058461538461538 at 0.5700000000000003\n",
      "Evaluating model model_0054999\n",
      "Done inferences in 2.0334243297576906 minutes at 2020-10-20 15:03:25.606056\n",
      "model_0054999 max f1 0.5234390584480352 at 0.5500000000000003\n",
      "Evaluating model model_0059999\n"
     ]
    }
   ],
   "source": [
    "# about 7 minutes each model (might be different depending on hardware configuration)\n",
    "the_max_iters = [49999, 54999, 59999, 64999, 69999, 74999, 79999, 84999, 89999, 94999, 99999] # these are the latest checkpoints while training\n",
    "the_model_names = [f\"model_{str(iters).zfill(7)}\" for iters in the_max_iters]\n",
    "model_bests, threshold_bests, f1_bests = evaluate_models(cfg, eval_dicts, the_model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best moodel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The  best model is {the_model_names[np.argmax(model_bests)]}')\n",
    "print(f'Its  score  threshold is {threshold_bests[np.argmax(model_bests)]}')\n",
    "print(f'Its best f1 score is {max(model_bests)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the best model to produce outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from processing_utils import submissions_for_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_best_model = the_model_names[np.argmax(model_bests)]\n",
    "the_model_name =  the_best_model\n",
    "the_best_score_threshold = threshold_bests[np.argmax(model_bests)]\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, f\"{the_model_name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 7 minutes (might be different depending on hardware configuration)\n",
    "test1_output_items = predict(test1_dicts, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'test1'\n",
    "test1_output_lines = submissions_for_outputs(file_name, test1_dicts, test1_output_items, score_thresh_test=the_best_score_threshold, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 7 minutes (might be different depending on hardware configuration)\n",
    "test2_output_items = predict(test2_dicts, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'test2'\n",
    "test2_output_lines = submissions_for_outputs(file_name, test2_dicts, test2_output_items, score_thresh_test=the_best_score_threshold, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "Visualize 10 images from each test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reloading\n",
    "import vis_utils\n",
    "import importlib\n",
    "importlib.reload(vis_utils)\n",
    "from vis_utils import visualize_sample_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_sample_outputs(test1_dicts, test1_output_lines, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_sample_outputs(test1_dicts, test1_output_lines, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import detectron2.data.detection_utils as utils\n",
    "def predict_batches(eval_dicts, batch_size=10):\n",
    "    def get_test_batch(test_dicts, batch_size=batch_size):\n",
    "        l = len(test_dicts)\n",
    "        for ndx in range(0, l, batch_size):\n",
    "            batch_data = test_dicts[ndx:min(ndx+batch_size, l)]\n",
    "            ret = []\n",
    "            for dataset_dict in batch_data:\n",
    "                dataset_dict = copy.deepcopy(dataset_dict)\n",
    "                image = utils.read_image(dataset_dict.pop(\"file_name\"), format=\"BGR\").copy()\n",
    "                image = torch.from_numpy(image).permute(2, 0, 1)  # CHW\n",
    "                dataset_dict[\"image\"] = image\n",
    "                ret.append(dataset_dict)\n",
    "            # read data for it\n",
    "            yield ret\n",
    "    \n",
    "    output_items = []\n",
    "    for batch1 in get_test_batch(eval_dicts, batch_size=10):\n",
    "        batch_output_items = predict_with_tta(batch1, cfg, score_thresh_test=0.5)\n",
    "        output_items += batch_output_items\n",
    "    return output_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model_name =  the_best_model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, f\"{the_model_name}.pth\")\n",
    "cfg.TEST.AUG.MIN_SIZES = (600, 700)\n",
    "\n",
    "output_items = predict_batches(eval_dicts, batch_size=32)\n",
    "score_thresh_tests = np.arange(0.5, 1.0, 0.01)\n",
    "model_evals = evaluate_model(eval_dicts, output_items, score_thresh_tests)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(score_thresh_tests, model_evals)\n",
    "max_idx = np.argmax(model_evals)\n",
    "print(f'max f1 {model_evals[max_idx]} at {score_thresh_tests[max_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}